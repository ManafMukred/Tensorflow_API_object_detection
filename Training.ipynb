{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Niwwuzw7J66"
      },
      "source": [
        "# **Training** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIkKgJeg_wVH"
      },
      "source": [
        "#### Important!\n",
        "Scripts ```exporter_main_v2.py & model_main_tf2.py```\n",
        "should be run from withing the object_detection directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld51-Sn67RaZ"
      },
      "source": [
        "In order to have a smooth training for our data, we have to install all related dependencies for our training process.\n",
        "\n",
        "We will use **%%capture** below which is a simple way to suppress unwanted output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Y27rqF_hGI"
      },
      "source": [
        "### Installing dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xCuGb17RNYB"
      },
      "outputs": [],
      "source": [
        "# Installing dependencies\n",
        "%%capture \n",
        "\n",
        "!pip install tensorflow-gpu\n",
        "!pip install tf_slim\n",
        "!pip install lvis\n",
        "!pip install tensorflow_io\n",
        "!pip install tf-models-official\n",
        "!pip install --upgrade opencv-python\n",
        "!pip install --upgrade opencv-contrib-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEGpXLl3tQVX"
      },
      "source": [
        "### Cloning TensorFlow object detection 2.0 models from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFkdXoEltLY9"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "\n",
        "# !git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nMHtlKqhrhM",
        "outputId": "288ad865-a8ba-4d2e-a242-ab69b91f30f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/Othercomputers/work_od/od/models/research\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/Othercomputers/work_od/od/models/research/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYndO972GX_F"
      },
      "source": [
        "Tensorflow Object Detection API uses Protobufs to configure model and training parameters. Before the framework can be used, the Protobuf libraries must be downloaded and compiled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BVaFu74iDYW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9Mcgze3GjSm"
      },
      "source": [
        "In TensorFlow 2.x, the pycocotools package is listed as a dependency of the Object Detection API. So we should get it installed when using the Object Detection API "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEsmIkv58c2b"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !git clone https://github.com/cocodataset/cocoapi.git\n",
        "!cd cocoapi/PythonAPI\n",
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be6JMuAH75rc"
      },
      "outputs": [],
      "source": [
        "!cp -r pycocotools /content/drive/Othercomputers/work_od/od/models/research/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "570AwOo175t1"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/Othercomputers/work_od/od/models/research/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pL89yEaHaaE"
      },
      "source": [
        "Installing the object_detection package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doTa7DIa75we"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uub0PapIluE"
      },
      "source": [
        "### Modifying our configuration file for the first model\n",
        "\n",
        "We need to specify our learning rate, epochs, training path and other instructions in ```pipeline.config```  file for each model before the start of the actual training process \n",
        "\n",
        "When opening that file, there are many hyperparameters to manipulate and fine-tune for further improvements, but here we are focusing on the ones we need for our project.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yvvGyKqKA7r"
      },
      "source": [
        "Setting the number of classes (in our case we have 3)\n",
        "```\n",
        " num_classes: 3 \n",
        " ```\n",
        "Setting our batch_size (we used low number due to memory limit in Colab free resources)\n",
        " ```\n",
        "batch_size: 8 \n",
        "```\n",
        "\n",
        " \n",
        "Setting the path to our desired model (SSD MobileNet_v2_320x320 OR efficientdet_d0_coco17_tpu_32) and specify the path to checkpoint of pre-trained model\n",
        "```\n",
        "fine_tune_checkpoint: \"path_to_pre-trained-model/checkpoint/ckpt-0\" \n",
        "```\n",
        "setting the desired number of steps\n",
        "```\n",
        "num_steps: 2000\n",
        "```\n",
        "\n",
        "we will set this to \"detection\" instead of classification\n",
        "```\n",
        "fine_tune_checkpoint_type: \"detection\" \n",
        "```\n",
        "\n",
        "the last two lines below will be set one time for train.record and one time for test.record\n",
        "```\n",
        "label_map_path: \"annotations/label_map.pbtxt\" # Path to label map file\n",
        "input_path: \"annotations/train.record\" # Path to training TFRecord file\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS8HXs_IH6-M"
      },
      "source": [
        "### Starting The Training \n",
        "\n",
        "After installing all necessary dependencies, we can now start our training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbqmOIvQN5vw"
      },
      "source": [
        "##### The first model: SSD MobileNet_v2_320x320"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRdbm9LlsMKw",
        "outputId": "98aea474-39e2-4551-c438-dcf5db5e9037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-28 10:32:14.163729: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0128 10:32:14.185370 140186872555392 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0128 10:32:14.187294 140186872555392 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0128 10:32:15.111933 140186872555392 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0128 10:32:15.112276 140186872555392 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0128 10:32:15.220786 140186872555392 deprecation.py:347] From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "I0128 10:32:15.523766 140186872555392 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "I0128 10:32:15.524568 140186872555392 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0128 10:32:15.524769 140186872555392 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0128 10:32:15.524840 140186872555392 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0128 10:32:15.535405 140186872555392 deprecation.py:347] From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0128 10:32:15.608360 140186872555392 deprecation.py:347] From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0128 10:32:26.152171 140186872555392 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0128 10:32:31.407082 140186872555392 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0128 10:32:36.663852 140186872555392 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2022-01-28 10:32:41.930657: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "2022-01-28 10:32:43.602848: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 10:32:54.546799 140184178210560 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 10:32:54.547179 140184178210560 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 10:32:54.547329 140184178210560 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 10:32:54.547471 140184178210560 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 10:32:54.547592 140184178210560 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 10:32:54.547726 140184178210560 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "2022-01-28 10:33:24.441515: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0128 10:33:25.520215 140184220174080 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 6.290s\n",
            "I0128 10:43:53.991010 140186872555392 model_lib_v2.py:700] Step 100 per-step time 6.290s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.41725704,\n",
            " 'Loss/localization_loss': 0.17854181,\n",
            " 'Loss/regularization_loss': 0.13241902,\n",
            " 'Loss/total_loss': 0.72821784,\n",
            " 'learning_rate': 0.19999701}\n",
            "I0128 10:43:53.991600 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.41725704,\n",
            " 'Loss/localization_loss': 0.17854181,\n",
            " 'Loss/regularization_loss': 0.13241902,\n",
            " 'Loss/total_loss': 0.72821784,\n",
            " 'learning_rate': 0.19999701}\n",
            "INFO:tensorflow:Step 200 per-step time 6.292s\n",
            "I0128 10:54:23.160530 140186872555392 model_lib_v2.py:700] Step 200 per-step time 6.292s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.40540805,\n",
            " 'Loss/localization_loss': 0.21806839,\n",
            " 'Loss/regularization_loss': 0.13427387,\n",
            " 'Loss/total_loss': 0.7577503,\n",
            " 'learning_rate': 0.26666403}\n",
            "I0128 10:54:23.161005 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.40540805,\n",
            " 'Loss/localization_loss': 0.21806839,\n",
            " 'Loss/regularization_loss': 0.13427387,\n",
            " 'Loss/total_loss': 0.7577503,\n",
            " 'learning_rate': 0.26666403}\n",
            "INFO:tensorflow:Step 300 per-step time 6.078s\n",
            "I0128 11:04:31.006373 140186872555392 model_lib_v2.py:700] Step 300 per-step time 6.078s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.312241,\n",
            " 'Loss/localization_loss': 0.16576913,\n",
            " 'Loss/regularization_loss': 0.14121716,\n",
            " 'Loss/total_loss': 0.6192273,\n",
            " 'learning_rate': 0.33333102}\n",
            "I0128 11:04:31.006909 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.312241,\n",
            " 'Loss/localization_loss': 0.16576913,\n",
            " 'Loss/regularization_loss': 0.14121716,\n",
            " 'Loss/total_loss': 0.6192273,\n",
            " 'learning_rate': 0.33333102}\n",
            "INFO:tensorflow:Step 400 per-step time 6.144s\n",
            "I0128 11:14:45.346969 140186872555392 model_lib_v2.py:700] Step 400 per-step time 6.144s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2480326,\n",
            " 'Loss/localization_loss': 0.1167635,\n",
            " 'Loss/regularization_loss': 0.14452511,\n",
            " 'Loss/total_loss': 0.5093212,\n",
            " 'learning_rate': 0.399998}\n",
            "I0128 11:14:45.347458 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.2480326,\n",
            " 'Loss/localization_loss': 0.1167635,\n",
            " 'Loss/regularization_loss': 0.14452511,\n",
            " 'Loss/total_loss': 0.5093212,\n",
            " 'learning_rate': 0.399998}\n",
            "INFO:tensorflow:Step 500 per-step time 6.018s\n",
            "I0128 11:24:47.141710 140186872555392 model_lib_v2.py:700] Step 500 per-step time 6.018s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.29893073,\n",
            " 'Loss/localization_loss': 0.11157328,\n",
            " 'Loss/regularization_loss': 0.1507447,\n",
            " 'Loss/total_loss': 0.5612487,\n",
            " 'learning_rate': 0.46666503}\n",
            "I0128 11:24:47.142212 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.29893073,\n",
            " 'Loss/localization_loss': 0.11157328,\n",
            " 'Loss/regularization_loss': 0.1507447,\n",
            " 'Loss/total_loss': 0.5612487,\n",
            " 'learning_rate': 0.46666503}\n",
            "INFO:tensorflow:Step 600 per-step time 6.021s\n",
            "I0128 11:34:49.231013 140186872555392 model_lib_v2.py:700] Step 600 per-step time 6.021s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2643386,\n",
            " 'Loss/localization_loss': 0.15862954,\n",
            " 'Loss/regularization_loss': 0.23157522,\n",
            " 'Loss/total_loss': 0.6545434,\n",
            " 'learning_rate': 0.53333205}\n",
            "I0128 11:34:49.231545 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.2643386,\n",
            " 'Loss/localization_loss': 0.15862954,\n",
            " 'Loss/regularization_loss': 0.23157522,\n",
            " 'Loss/total_loss': 0.6545434,\n",
            " 'learning_rate': 0.53333205}\n",
            "INFO:tensorflow:Step 700 per-step time 6.030s\n",
            "I0128 11:44:52.222746 140186872555392 model_lib_v2.py:700] Step 700 per-step time 6.030s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6179436,\n",
            " 'Loss/localization_loss': 0.22951809,\n",
            " 'Loss/regularization_loss': 0.7281424,\n",
            " 'Loss/total_loss': 1.575604,\n",
            " 'learning_rate': 0.599999}\n",
            "I0128 11:44:52.223210 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.6179436,\n",
            " 'Loss/localization_loss': 0.22951809,\n",
            " 'Loss/regularization_loss': 0.7281424,\n",
            " 'Loss/total_loss': 1.575604,\n",
            " 'learning_rate': 0.599999}\n",
            "INFO:tensorflow:Step 800 per-step time 6.009s\n",
            "I0128 11:54:53.155443 140186872555392 model_lib_v2.py:700] Step 800 per-step time 6.009s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 3.3749444,\n",
            " 'Loss/localization_loss': 0.24359894,\n",
            " 'Loss/regularization_loss': 0.87439823,\n",
            " 'Loss/total_loss': 4.492942,\n",
            " 'learning_rate': 0.66666603}\n",
            "I0128 11:54:53.155901 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 3.3749444,\n",
            " 'Loss/localization_loss': 0.24359894,\n",
            " 'Loss/regularization_loss': 0.87439823,\n",
            " 'Loss/total_loss': 4.492942,\n",
            " 'learning_rate': 0.66666603}\n",
            "INFO:tensorflow:Step 900 per-step time 6.015s\n",
            "I0128 12:04:54.684881 140186872555392 model_lib_v2.py:700] Step 900 per-step time 6.015s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2378561,\n",
            " 'Loss/localization_loss': 0.13807392,\n",
            " 'Loss/regularization_loss': 1.2866418,\n",
            " 'Loss/total_loss': 1.6625719,\n",
            " 'learning_rate': 0.733333}\n",
            "I0128 12:04:54.685330 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.2378561,\n",
            " 'Loss/localization_loss': 0.13807392,\n",
            " 'Loss/regularization_loss': 1.2866418,\n",
            " 'Loss/total_loss': 1.6625719,\n",
            " 'learning_rate': 0.733333}\n",
            "INFO:tensorflow:Step 1000 per-step time 5.961s\n",
            "I0128 12:14:50.779548 140186872555392 model_lib_v2.py:700] Step 1000 per-step time 5.961s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.41049692,\n",
            " 'Loss/localization_loss': 0.21864131,\n",
            " 'Loss/regularization_loss': 1.270449,\n",
            " 'Loss/total_loss': 1.8995873,\n",
            " 'learning_rate': 0.8}\n",
            "I0128 12:14:50.779975 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.41049692,\n",
            " 'Loss/localization_loss': 0.21864131,\n",
            " 'Loss/regularization_loss': 1.270449,\n",
            " 'Loss/total_loss': 1.8995873,\n",
            " 'learning_rate': 0.8}\n",
            "INFO:tensorflow:Step 1100 per-step time 5.943s\n",
            "I0128 12:24:45.050812 140186872555392 model_lib_v2.py:700] Step 1100 per-step time 5.943s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2848584,\n",
            " 'Loss/localization_loss': 0.105790146,\n",
            " 'Loss/regularization_loss': 1.2663852,\n",
            " 'Loss/total_loss': 1.6570337,\n",
            " 'learning_rate': 0.7804226}\n",
            "I0128 12:24:45.051420 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.2848584,\n",
            " 'Loss/localization_loss': 0.105790146,\n",
            " 'Loss/regularization_loss': 1.2663852,\n",
            " 'Loss/total_loss': 1.6570337,\n",
            " 'learning_rate': 0.7804226}\n",
            "INFO:tensorflow:Step 1200 per-step time 5.938s\n",
            "I0128 12:34:38.846752 140186872555392 model_lib_v2.py:700] Step 1200 per-step time 5.938s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.333603,\n",
            " 'Loss/localization_loss': 0.17365964,\n",
            " 'Loss/regularization_loss': 1.1974435,\n",
            " 'Loss/total_loss': 1.7047062,\n",
            " 'learning_rate': 0.72360677}\n",
            "I0128 12:34:38.847242 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.333603,\n",
            " 'Loss/localization_loss': 0.17365964,\n",
            " 'Loss/regularization_loss': 1.1974435,\n",
            " 'Loss/total_loss': 1.7047062,\n",
            " 'learning_rate': 0.72360677}\n",
            "INFO:tensorflow:Step 1300 per-step time 6.032s\n",
            "I0128 12:44:42.022319 140186872555392 model_lib_v2.py:700] Step 1300 per-step time 6.032s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19189967,\n",
            " 'Loss/localization_loss': 0.10086869,\n",
            " 'Loss/regularization_loss': 1.1381571,\n",
            " 'Loss/total_loss': 1.4309255,\n",
            " 'learning_rate': 0.63511413}\n",
            "I0128 12:44:42.022766 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.19189967,\n",
            " 'Loss/localization_loss': 0.10086869,\n",
            " 'Loss/regularization_loss': 1.1381571,\n",
            " 'Loss/total_loss': 1.4309255,\n",
            " 'learning_rate': 0.63511413}\n",
            "INFO:tensorflow:Step 1400 per-step time 5.901s\n",
            "I0128 12:54:32.166767 140186872555392 model_lib_v2.py:700] Step 1400 per-step time 5.901s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1583188,\n",
            " 'Loss/localization_loss': 0.06349772,\n",
            " 'Loss/regularization_loss': 1.0923752,\n",
            " 'Loss/total_loss': 1.3141916,\n",
            " 'learning_rate': 0.5236068}\n",
            "I0128 12:54:32.167282 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.1583188,\n",
            " 'Loss/localization_loss': 0.06349772,\n",
            " 'Loss/regularization_loss': 1.0923752,\n",
            " 'Loss/total_loss': 1.3141916,\n",
            " 'learning_rate': 0.5236068}\n",
            "INFO:tensorflow:Step 1500 per-step time 5.897s\n",
            "I0128 13:04:21.912092 140186872555392 model_lib_v2.py:700] Step 1500 per-step time 5.897s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16366662,\n",
            " 'Loss/localization_loss': 0.086301655,\n",
            " 'Loss/regularization_loss': 1.0538843,\n",
            " 'Loss/total_loss': 1.3038526,\n",
            " 'learning_rate': 0.39999998}\n",
            "I0128 13:04:21.912615 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.16366662,\n",
            " 'Loss/localization_loss': 0.086301655,\n",
            " 'Loss/regularization_loss': 1.0538843,\n",
            " 'Loss/total_loss': 1.3038526,\n",
            " 'learning_rate': 0.39999998}\n",
            "INFO:tensorflow:Step 1600 per-step time 5.910s\n",
            "I0128 13:14:12.887326 140186872555392 model_lib_v2.py:700] Step 1600 per-step time 5.910s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17263113,\n",
            " 'Loss/localization_loss': 0.071622096,\n",
            " 'Loss/regularization_loss': 1.0259213,\n",
            " 'Loss/total_loss': 1.2701746,\n",
            " 'learning_rate': 0.27639318}\n",
            "I0128 13:14:12.887853 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.17263113,\n",
            " 'Loss/localization_loss': 0.071622096,\n",
            " 'Loss/regularization_loss': 1.0259213,\n",
            " 'Loss/total_loss': 1.2701746,\n",
            " 'learning_rate': 0.27639318}\n",
            "INFO:tensorflow:Step 1700 per-step time 5.905s\n",
            "I0128 13:24:03.431523 140186872555392 model_lib_v2.py:700] Step 1700 per-step time 5.905s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24725236,\n",
            " 'Loss/localization_loss': 0.06556167,\n",
            " 'Loss/regularization_loss': 1.0077055,\n",
            " 'Loss/total_loss': 1.3205194,\n",
            " 'learning_rate': 0.16488583}\n",
            "I0128 13:24:03.431988 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.24725236,\n",
            " 'Loss/localization_loss': 0.06556167,\n",
            " 'Loss/regularization_loss': 1.0077055,\n",
            " 'Loss/total_loss': 1.3205194,\n",
            " 'learning_rate': 0.16488583}\n",
            "INFO:tensorflow:Step 1800 per-step time 5.901s\n",
            "I0128 13:33:53.500106 140186872555392 model_lib_v2.py:700] Step 1800 per-step time 5.901s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11904135,\n",
            " 'Loss/localization_loss': 0.049083304,\n",
            " 'Loss/regularization_loss': 0.99763966,\n",
            " 'Loss/total_loss': 1.1657643,\n",
            " 'learning_rate': 0.07639318}\n",
            "I0128 13:33:53.500627 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.11904135,\n",
            " 'Loss/localization_loss': 0.049083304,\n",
            " 'Loss/regularization_loss': 0.99763966,\n",
            " 'Loss/total_loss': 1.1657643,\n",
            " 'learning_rate': 0.07639318}\n",
            "INFO:tensorflow:Step 1900 per-step time 5.938s\n",
            "I0128 13:43:47.253520 140186872555392 model_lib_v2.py:700] Step 1900 per-step time 5.938s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.28845483,\n",
            " 'Loss/localization_loss': 0.100757204,\n",
            " 'Loss/regularization_loss': 0.99359107,\n",
            " 'Loss/total_loss': 1.3828032,\n",
            " 'learning_rate': 0.019577408}\n",
            "I0128 13:43:47.254125 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.28845483,\n",
            " 'Loss/localization_loss': 0.100757204,\n",
            " 'Loss/regularization_loss': 0.99359107,\n",
            " 'Loss/total_loss': 1.3828032,\n",
            " 'learning_rate': 0.019577408}\n",
            "INFO:tensorflow:Step 2000 per-step time 5.897s\n",
            "I0128 13:53:36.946624 140186872555392 model_lib_v2.py:700] Step 2000 per-step time 5.897s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18737164,\n",
            " 'Loss/localization_loss': 0.0866009,\n",
            " 'Loss/regularization_loss': 0.9928783,\n",
            " 'Loss/total_loss': 1.2668508,\n",
            " 'learning_rate': 0.0}\n",
            "I0128 13:53:36.947163 140186872555392 model_lib_v2.py:701] {'Loss/classification_loss': 0.18737164,\n",
            " 'Loss/localization_loss': 0.0866009,\n",
            " 'Loss/regularization_loss': 0.9928783,\n",
            " 'Loss/total_loss': 1.2668508,\n",
            " 'learning_rate': 0.0}\n"
          ]
        }
      ],
      "source": [
        "#train mobilenet\n",
        "%cd /content/drive/Othercomputers/work_od/od/rps_object_detection/\n",
        "!python model_main_tf2.py --model_dir=/content/drive/Othercomputers/work_od/od/training_space/models_config/mobilenet --pipeline_config_path=/content/drive/Othercomputers/work_od/od/training_space/models_config/mobilenet/pipeline.config --alsologtostderr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTtWIvYiOZFQ"
      },
      "source": [
        "Exporting our trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ogUSVxFK0P",
        "outputId": "63006068-6766-4c97-d51f-89bd65197338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-28 13:56:58.966115: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0128 13:56:59.670502 140205564520320 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 13:57:07.691619 140205564520320 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 13:57:07.692265 140205564520320 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 13:57:07.692581 140205564520320 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 13:57:07.692838 140205564520320 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 13:57:07.693350 140205564520320 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0128 13:57:07.693684 140205564520320 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f839e2bcbd0>, because it is not built.\n",
            "W0128 13:57:20.791990 140205564520320 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f839e2bcbd0>, because it is not built.\n",
            "2022-01-28 13:57:34.421248: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0128 13:57:55.605566 140205564520320 save.py:268] Found untraced functions such as BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, BoxPredictor_layer_call_and_return_conditional_losses while saving (showing 5 of 125). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_mobilenet/saved_model/assets\n",
            "I0128 13:58:02.295956 140205564520320 builder_impl.py:784] Assets written to: /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_mobilenet/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_mobilenet/pipeline.config\n",
            "I0128 13:58:03.069204 140205564520320 config_util.py:254] Writing pipeline config file to /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_mobilenet/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/drive/Othercomputers/work_od/od/training_space/models_config/mobilenet/pipeline.config --trained_checkpoint_dir /content/drive/Othercomputers/work_od/od/training_space/models_config/mobilenet --output_directory /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_mobilenet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhJFH0LzOsnp"
      },
      "source": [
        "##### The Second model: Efficientdet_d0_coco17_tpu_32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgIbZh9RgoOL",
        "outputId": "f2bbf770-0f41-4931-a933-70951adb1996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-12-19 23:50:10.268738: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I1219 23:50:10.272590 140272885966720 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I1219 23:50:10.995187 140272885966720 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1219 23:50:10.995453 140272885966720 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "I1219 23:50:11.006850 140272885966720 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1219 23:50:11.006979 140272885966720 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I1219 23:50:11.007094 140272885966720 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I1219 23:50:11.012130 140272885966720 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.037208 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.039177 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.041548 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.042671 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.050822 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.055126 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.061909 140272885966720 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1219 23:50:11.062036 140272885966720 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.079882 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.081024 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.083028 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.084162 140272885966720 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1219 23:50:11.177742 140272885966720 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1219 23:50:11.177917 140272885966720 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1219 23:50:11.480549 140272885966720 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1219 23:50:11.480795 140272885966720 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1219 23:50:11.791447 140272885966720 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1219 23:50:11.791672 140272885966720 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1219 23:50:12.265861 140272885966720 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1219 23:50:12.266088 140272885966720 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1219 23:50:12.736914 140272885966720 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1219 23:50:12.737135 140272885966720 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1219 23:50:13.337407 140272885966720 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1219 23:50:13.337619 140272885966720 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I1219 23:50:13.487048 140272885966720 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I1219 23:50:13.547776 140272885966720 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1219 23:50:13.601702 140272885966720 deprecation.py:347] From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "I1219 23:50:13.613318 140272885966720 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "I1219 23:50:13.613964 140272885966720 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/Othercomputers/work_od/od/training_space/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1219 23:50:13.614151 140272885966720 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1219 23:50:13.614350 140272885966720 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1219 23:50:13.617046 140272885966720 deprecation.py:347] From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1219 23:50:13.638959 140272885966720 deprecation.py:347] From /content/drive/Othercomputers/work_od/od/rps_object_detection/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1219 23:50:22.587649 140272885966720 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1219 23:50:27.636827 140272885966720 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-12-19 23:50:31.935745: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1219 23:51:18.588944 140267989460736 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W1219 23:51:31.101320 140267989460736 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W1219 23:51:48.152574 140267989460736 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W1219 23:52:04.197602 140267989460736 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "W1219 23:52:20.221882 140267989460736 utils.py:80] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "INFO:tensorflow:Step 100 per-step time 3.306s\n",
            "I1219 23:56:48.734729 140272885966720 model_lib_v2.py:700] Step 100 per-step time 3.306s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.68567246,\n",
            " 'Loss/localization_loss': 0.017099978,\n",
            " 'Loss/regularization_loss': 0.028347094,\n",
            " 'Loss/total_loss': 0.7311195,\n",
            " 'learning_rate': 0.0089}\n",
            "I1219 23:56:48.735177 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.68567246,\n",
            " 'Loss/localization_loss': 0.017099978,\n",
            " 'Loss/regularization_loss': 0.028347094,\n",
            " 'Loss/total_loss': 0.7311195,\n",
            " 'learning_rate': 0.0089}\n",
            "INFO:tensorflow:Step 200 per-step time 2.347s\n",
            "I1220 00:00:43.471547 140272885966720 model_lib_v2.py:700] Step 200 per-step time 2.347s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3026068,\n",
            " 'Loss/localization_loss': 0.00829954,\n",
            " 'Loss/regularization_loss': 0.028369386,\n",
            " 'Loss/total_loss': 0.33927572,\n",
            " 'learning_rate': 0.0168}\n",
            "I1220 00:00:43.471940 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.3026068,\n",
            " 'Loss/localization_loss': 0.00829954,\n",
            " 'Loss/regularization_loss': 0.028369386,\n",
            " 'Loss/total_loss': 0.33927572,\n",
            " 'learning_rate': 0.0168}\n",
            "INFO:tensorflow:Step 300 per-step time 2.348s\n",
            "I1220 00:04:38.233346 140272885966720 model_lib_v2.py:700] Step 300 per-step time 2.348s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2216154,\n",
            " 'Loss/localization_loss': 0.0061414745,\n",
            " 'Loss/regularization_loss': 0.028421242,\n",
            " 'Loss/total_loss': 0.25617814,\n",
            " 'learning_rate': 0.024699999}\n",
            "I1220 00:04:38.233741 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.2216154,\n",
            " 'Loss/localization_loss': 0.0061414745,\n",
            " 'Loss/regularization_loss': 0.028421242,\n",
            " 'Loss/total_loss': 0.25617814,\n",
            " 'learning_rate': 0.024699999}\n",
            "INFO:tensorflow:Step 400 per-step time 2.340s\n",
            "I1220 00:08:32.213003 140272885966720 model_lib_v2.py:700] Step 400 per-step time 2.340s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22812565,\n",
            " 'Loss/localization_loss': 0.0045679305,\n",
            " 'Loss/regularization_loss': 0.028491762,\n",
            " 'Loss/total_loss': 0.26118532,\n",
            " 'learning_rate': 0.032599997}\n",
            "I1220 00:08:32.213382 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.22812565,\n",
            " 'Loss/localization_loss': 0.0045679305,\n",
            " 'Loss/regularization_loss': 0.028491762,\n",
            " 'Loss/total_loss': 0.26118532,\n",
            " 'learning_rate': 0.032599997}\n",
            "INFO:tensorflow:Step 500 per-step time 2.338s\n",
            "I1220 00:12:26.021355 140272885966720 model_lib_v2.py:700] Step 500 per-step time 2.338s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22020562,\n",
            " 'Loss/localization_loss': 0.0054784776,\n",
            " 'Loss/regularization_loss': 0.028601304,\n",
            " 'Loss/total_loss': 0.2542854,\n",
            " 'learning_rate': 0.040499996}\n",
            "I1220 00:12:26.021808 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.22020562,\n",
            " 'Loss/localization_loss': 0.0054784776,\n",
            " 'Loss/regularization_loss': 0.028601304,\n",
            " 'Loss/total_loss': 0.2542854,\n",
            " 'learning_rate': 0.040499996}\n",
            "INFO:tensorflow:Step 600 per-step time 2.358s\n",
            "I1220 00:16:21.788557 140272885966720 model_lib_v2.py:700] Step 600 per-step time 2.358s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20537633,\n",
            " 'Loss/localization_loss': 0.0037353907,\n",
            " 'Loss/regularization_loss': 0.028707009,\n",
            " 'Loss/total_loss': 0.23781873,\n",
            " 'learning_rate': 0.048399996}\n",
            "I1220 00:16:21.788983 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.20537633,\n",
            " 'Loss/localization_loss': 0.0037353907,\n",
            " 'Loss/regularization_loss': 0.028707009,\n",
            " 'Loss/total_loss': 0.23781873,\n",
            " 'learning_rate': 0.048399996}\n",
            "INFO:tensorflow:Step 700 per-step time 2.357s\n",
            "I1220 00:20:17.529361 140272885966720 model_lib_v2.py:700] Step 700 per-step time 2.357s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27128798,\n",
            " 'Loss/localization_loss': 0.0044170017,\n",
            " 'Loss/regularization_loss': 0.028908014,\n",
            " 'Loss/total_loss': 0.304613,\n",
            " 'learning_rate': 0.056299996}\n",
            "I1220 00:20:17.529788 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.27128798,\n",
            " 'Loss/localization_loss': 0.0044170017,\n",
            " 'Loss/regularization_loss': 0.028908014,\n",
            " 'Loss/total_loss': 0.304613,\n",
            " 'learning_rate': 0.056299996}\n",
            "INFO:tensorflow:Step 800 per-step time 2.354s\n",
            "I1220 00:24:12.894102 140272885966720 model_lib_v2.py:700] Step 800 per-step time 2.354s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15544069,\n",
            " 'Loss/localization_loss': 0.0029359208,\n",
            " 'Loss/regularization_loss': 0.029057961,\n",
            " 'Loss/total_loss': 0.18743457,\n",
            " 'learning_rate': 0.0642}\n",
            "I1220 00:24:12.894501 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.15544069,\n",
            " 'Loss/localization_loss': 0.0029359208,\n",
            " 'Loss/regularization_loss': 0.029057961,\n",
            " 'Loss/total_loss': 0.18743457,\n",
            " 'learning_rate': 0.0642}\n",
            "INFO:tensorflow:Step 900 per-step time 2.365s\n",
            "I1220 00:28:09.352864 140272885966720 model_lib_v2.py:700] Step 900 per-step time 2.365s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12594366,\n",
            " 'Loss/localization_loss': 0.0021257743,\n",
            " 'Loss/regularization_loss': 0.029186523,\n",
            " 'Loss/total_loss': 0.15725595,\n",
            " 'learning_rate': 0.0721}\n",
            "I1220 00:28:09.353240 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.12594366,\n",
            " 'Loss/localization_loss': 0.0021257743,\n",
            " 'Loss/regularization_loss': 0.029186523,\n",
            " 'Loss/total_loss': 0.15725595,\n",
            " 'learning_rate': 0.0721}\n",
            "INFO:tensorflow:Step 1000 per-step time 2.349s\n",
            "I1220 00:32:04.250288 140272885966720 model_lib_v2.py:700] Step 1000 per-step time 2.349s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15428181,\n",
            " 'Loss/localization_loss': 0.0025445542,\n",
            " 'Loss/regularization_loss': 0.029429574,\n",
            " 'Loss/total_loss': 0.18625593,\n",
            " 'learning_rate': nan}\n",
            "I1220 00:32:04.250709 140272885966720 model_lib_v2.py:701] {'Loss/classification_loss': 0.15428181,\n",
            " 'Loss/localization_loss': 0.0025445542,\n",
            " 'Loss/regularization_loss': 0.029429574,\n",
            " 'Loss/total_loss': 0.18625593,\n",
            " 'learning_rate': nan}\n"
          ]
        }
      ],
      "source": [
        "#train efficientdet_d0_coco17_tpu_32\n",
        "!python model_main_tf2.py --model_dir=/content/drive/Othercomputers/work_od/od/training_space/models_config/efficientdet_d0_coco17_tpu_32 --pipeline_config_path=/content/drive/Othercomputers/work_od/od/training_space/models_config/efficientdet_d0_coco17_tpu_32/pipeline.config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tfhueu4HnHI",
        "outputId": "44aae8b0-1b41-4564-af27-1b9272bc9925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-03 05:34:26.208480: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "I0103 05:34:26.254548 140308114024320 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0103 05:34:26.254778 140308114024320 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0103 05:34:26.254869 140308114024320 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0103 05:34:26.258966 140308114024320 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0103 05:34:26.316798 140308114024320 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0103 05:34:26.316976 140308114024320 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0103 05:34:26.381664 140308114024320 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0103 05:34:26.381856 140308114024320 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0103 05:34:26.545325 140308114024320 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0103 05:34:26.545505 140308114024320 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0103 05:34:26.716224 140308114024320 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0103 05:34:26.716411 140308114024320 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0103 05:34:26.986003 140308114024320 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0103 05:34:26.986223 140308114024320 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0103 05:34:27.379072 140308114024320 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0103 05:34:27.379285 140308114024320 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0103 05:34:27.773945 140308114024320 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0103 05:34:27.774149 140308114024320 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0103 05:34:27.877306 140308114024320 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0103 05:34:27.938133 140308114024320 efficientnet_model.py:457] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0103 05:34:30.590617 140308114024320 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f9b7d616090>, because it is not built.\n",
            "W0103 05:34:53.766990 140308114024320 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f9b7d616090>, because it is not built.\n",
            "2022-01-03 05:35:20.046668: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0103 05:36:00.158044 140308114024320 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 795). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_efficientdet_d0_coco17_tpu_32/saved_model/assets\n",
            "I0103 05:36:22.009670 140308114024320 builder_impl.py:784] Assets written to: /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_efficientdet_d0_coco17_tpu_32/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_efficientdet_d0_coco17_tpu_32/pipeline.config\n",
            "I0103 05:36:23.721011 140308114024320 config_util.py:254] Writing pipeline config file to /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_efficientdet_d0_coco17_tpu_32/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "#export efficientdet_d0_coco17_tpu_32 \n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/drive/Othercomputers/work_od/od/training_space/models_config/efficientdet_d0_coco17_tpu_32/pipeline.config --trained_checkpoint_dir /content/drive/Othercomputers/work_od/od/training_space/models_config/efficientdet_d0_coco17_tpu_32 --output_directory /content/drive/Othercomputers/work_od/od/training_space/exported_models/exported_efficientdet_d0_coco17_tpu_32\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
